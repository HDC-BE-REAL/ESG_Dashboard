"""
ESG ë³´ê³ ì„œì—ì„œ ë°°ì¶œëŸ‰ ë°ì´í„° ì¶”ì¶œ

Usage:
    from app.services.emission_extractor import EmissionExtractor

    extractor = EmissionExtractor()
    data = extractor.extract_for_document(doc_id=2)
    extractor.save_to_summary(data)

    # GPT ê¸°ë°˜ ì¶”ì¶œ (ë” ìœ ì—°í•œ íŒ¨í„´ ì¸ì‹)
    data = extractor.extract_for_document(doc_id=2, use_gpt=True)
"""

import os
import re
import json
import base64
from pathlib import Path
from typing import Optional, Dict, Any, List, Union
from decimal import Decimal
from sqlalchemy import text
from openai import OpenAI
from dotenv import load_dotenv
from ..database import engine

load_dotenv()

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# PDF ì¶”ì¶œ ê²°ê³¼ ê²½ë¡œ (í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì • ê°€ëŠ¥)
STRUCTURED_DATA_PATH = Path(os.getenv("STRUCTURED_DATA_PATH", "../PDF_Extraction/data/pages_structured"))


class EmissionExtractor:
    """table_cellsì—ì„œ ë°°ì¶œëŸ‰ ë°ì´í„° ì¶”ì¶œ"""

    # í‚¤ì›Œë“œ íŒ¨í„´ (ì •ê·œì‹)
    SCOPE1_PATTERNS = [
        r'ì§ì ‘.*ì˜¨ì‹¤ê°€ìŠ¤.*Scope.?1',
        r'ì§ì ‘ì˜¨ì‹¤ê°€ìŠ¤ë°°ì¶œ.*Scope.?1',
        r'Scope.?1.*ì§ì ‘',
        r'^ì§ì ‘ë°°ì¶œ',
    ]

    SCOPE2_PATTERNS = [
        r'ê°„ì ‘.*ì˜¨ì‹¤ê°€ìŠ¤.*Scope.?2',
        r'ê°„ì ‘ì˜¨ì‹¤ê°€ìŠ¤ë°°ì¶œ.*Scope.?2',
        r'Scope.?2.*ê°„ì ‘',
        r'^ê°„ì ‘ë°°ì¶œ',
    ]

    SCOPE1_2_PATTERNS = [
        r'Scope.?1.?&.?2',
        r'Scope.?1.?2',
        r'ì§.?ê°„ì ‘.*ì˜¨ì‹¤ê°€ìŠ¤',
        r'ì§/ê°„ì ‘',
    ]

    SCOPE3_PATTERNS = [
        r'Scope.?3',
        r'ê¸°íƒ€.*ê°„ì ‘.*ì˜¨ì‹¤ê°€ìŠ¤',
    ]

    def extract_for_document(self, doc_id: int, use_gpt: Union[bool, str] = False) -> Dict[str, Any]:
        """
        ë‹¨ì¼ ë¬¸ì„œì—ì„œ ëª¨ë“  ESG ìˆ˜ì¹˜ ì¶”ì¶œ

        Args:
            doc_id: ë¬¸ì„œ ID
            use_gpt: ì¶”ì¶œ ë°©ì‹ ì„ íƒ
                - False: ì •ê·œì‹ íŒ¨í„´ (ë¹ ë¦„, ë¬´ë£Œ)
                - True: GPT í…ìŠ¤íŠ¸ ë¶„ì„ (ìœ ì—°í•¨, $0.001/íšŒì‚¬)
                - 'vision': GPT-4V ì´ë¯¸ì§€ ë¶„ì„ (ê°€ì¥ ì •í™•, $0.05/íšŒì‚¬)

        Returns:
            {
                'doc_id': 2,
                'company_name': 'HDEC',
                'report_year': 2025,
                'data_year': 2024,
                's1': 137450.0,
                's2': 113234.0,
                's3': 5198461.0,
                'revenue': 326703.0,
                'yearly_emissions': {'2021': 296841, '2022': 384836, ...},
                'base_year': 2019,
                'base_emissions': 596140.0,
                'source_tables': {'s1': 151, 's2': 151, 's3': 281, 'revenue': 72},
                'allowance': 100273.6,  # ì¶”ì •ì¹˜
                'data_source': 'auto' | 'gpt'
            }
        """
        result = {
            'doc_id': doc_id,
            'source_tables': {},
            'data_source': 'auto'
        }

        # 1. ë¬¸ì„œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        doc_info = self._get_document_info(doc_id)
        if not doc_info:
            raise ValueError(f"Document {doc_id} not found")

        result['company_name'] = doc_info['company_name']
        result['report_year'] = doc_info['report_year']
        result['data_year'] = doc_info['report_year'] - 1  # ë³´í†µ ì „ë…„ë„ ë°ì´í„°

        # 2. ë°°ì¶œëŸ‰ ê´€ë ¨ í‘œ ì°¾ê¸°
        if use_gpt:
            # GPT ëª¨ë“œ: ì œëª© í•„í„°ë§ ì—†ì´ ëª¨ë“  í‘œ ê²€í†  (ë‚´ìš© ê¸°ë°˜ íŒë‹¨)
            emission_tables = self._find_all_tables(doc_id)
            mode_name = "GPT-4V ì´ë¯¸ì§€" if use_gpt == 'vision' else "GPT í…ìŠ¤íŠ¸"
            print(f"[Extractor] ì „ì²´ í‘œ {len(emission_tables)}ê°œ ê²€í†  ({mode_name} ëª¨ë“œ)")
        else:
            # ì •ê·œì‹ ëª¨ë“œ: ì œëª©ìœ¼ë¡œ í•„í„°ë§ (ë¹ ë¥¸ ì²˜ë¦¬)
            emission_tables = self._find_emission_tables(doc_id)
            print(f"[Extractor] ë°°ì¶œëŸ‰ ê´€ë ¨ í‘œ {len(emission_tables)}ê°œ ë°œê²¬")

        # GPT ëª¨ë“œ: GPT APIë¡œ ì¶”ì¶œ
        if use_gpt:
            if use_gpt == 'vision':
                # GPT-4V ì´ë¯¸ì§€ ë¶„ì„
                result['data_source'] = 'gpt-vision'
                gpt_data = self._extract_with_gpt_vision(doc_id, emission_tables)
            else:
                # GPT í…ìŠ¤íŠ¸ ë¶„ì„
                result['data_source'] = 'gpt'
                gpt_data = self._extract_with_gpt(doc_id, emission_tables)

            if gpt_data:
                result.update(gpt_data)
                # í• ë‹¹ëŸ‰ ì¶”ì • (Scope 1+2ì˜ 40%)
                if result.get('s1') and result.get('s2'):
                    result['allowance'] = (result['s1'] + result['s2']) * 0.4
                return result
            else:
                print("[Extractor] GPT ì¶”ì¶œ ì‹¤íŒ¨, ì •ê·œì‹ fallback")

        # 3. Scope 1, 2 ì¶”ì¶œ (ì£¼ìš” í‘œì—ì„œ) - ì •ê·œì‹ ë°©ì‹
        scope_data = self._extract_scope_1_2(doc_id, emission_tables)
        if scope_data:
            result['s1'] = scope_data.get('s1')
            result['s2'] = scope_data.get('s2')
            result['yearly_emissions'] = scope_data.get('yearly')
            result['base_emissions'] = scope_data.get('base_emissions')
            result['base_year'] = scope_data.get('base_year')
            result['source_tables']['s1'] = scope_data.get('table_id')
            result['source_tables']['s2'] = scope_data.get('table_id')

        # 4. Scope 3 ì¶”ì¶œ
        scope3_data = self._extract_scope_3(doc_id, emission_tables)
        if scope3_data:
            result['s3'] = scope3_data.get('s3')
            result['source_tables']['s3'] = scope3_data.get('table_id')

        # 5. ë§¤ì¶œì•¡ ì¶”ì¶œ
        revenue_data = self._extract_revenue(doc_id)
        if revenue_data:
            result['revenue'] = revenue_data.get('revenue')
            result['source_tables']['revenue'] = revenue_data.get('table_id')

        # 6. í• ë‹¹ëŸ‰ ì¶”ì • (Scope 1+2ì˜ 40%)
        if result.get('s1') and result.get('s2'):
            result['allowance'] = (result['s1'] + result['s2']) * 0.4

        return result

    def _get_document_info(self, doc_id: int) -> Optional[Dict]:
        """ë¬¸ì„œ ë©”íƒ€ë°ì´í„° ì¡°íšŒ"""
        sql = """
            SELECT id, company_name, report_year, filename
            FROM documents
            WHERE id = :doc_id
        """
        with engine.connect() as conn:
            row = conn.execute(text(sql), {'doc_id': doc_id}).fetchone()
            if row:
                return {
                    'id': row[0],
                    'company_name': row[1],
                    'report_year': row[2],
                    'filename': row[3]
                }
        return None

    def _find_emission_tables(self, doc_id: int) -> List[Dict]:
        """ë°°ì¶œëŸ‰ ê´€ë ¨ í‘œ íƒìƒ‰ (ì œëª© í‚¤ì›Œë“œ ê¸°ë°˜)"""
        sql = """
            SELECT dt.id, dt.title, dt.page_no,
                   (SELECT COUNT(*) FROM table_cells tc WHERE tc.table_id = dt.id) as cell_count
            FROM doc_tables dt
            WHERE dt.doc_id = :doc_id
              AND (
                  dt.title LIKE '%ì˜¨ì‹¤ê°€ìŠ¤%'
                  OR dt.title LIKE '%ë°°ì¶œ%'
                  OR dt.title LIKE '%Scope%'
                  OR dt.title LIKE '%GHG%'
              )
            ORDER BY dt.page_no
        """
        with engine.connect() as conn:
            rows = conn.execute(text(sql), {'doc_id': doc_id}).fetchall()
            return [
                {'id': r[0], 'title': r[1], 'page_no': r[2], 'cell_count': r[3]}
                for r in rows
            ]

    def _find_all_tables(self, doc_id: int) -> List[Dict]:
        """ë¬¸ì„œì˜ ëª¨ë“  í‘œ ê°€ì ¸ì˜¤ê¸° (GPT ëª¨ë“œìš©, í‚¤ì›Œë“œ í‘œ ìš°ì„ ìˆœìœ„)"""
        # 1. í‚¤ì›Œë“œ ìˆëŠ” í‘œ (ìš°ì„ ìˆœìœ„ 1)
        sql_keyword = """
            SELECT dt.id, dt.title, dt.page_no,
                   (SELECT COUNT(*) FROM table_cells tc WHERE tc.table_id = dt.id) as cell_count,
                   1 as priority
            FROM doc_tables dt
            WHERE dt.doc_id = :doc_id
              AND (
                  dt.title LIKE '%ì˜¨ì‹¤ê°€ìŠ¤%'
                  OR dt.title LIKE '%ë°°ì¶œ%'
                  OR dt.title LIKE '%Scope%'
                  OR dt.title LIKE '%GHG%'
                  OR dt.title LIKE '%íƒ„ì†Œ%'
              )
            HAVING cell_count >= 20
        """

        # 2. ë‚˜ë¨¸ì§€ í° í‘œë“¤ (ìš°ì„ ìˆœìœ„ 2)
        sql_rest = """
            SELECT dt.id, dt.title, dt.page_no,
                   (SELECT COUNT(*) FROM table_cells tc WHERE tc.table_id = dt.id) as cell_count,
                   2 as priority
            FROM doc_tables dt
            WHERE dt.doc_id = :doc_id
              AND NOT (
                  dt.title LIKE '%ì˜¨ì‹¤ê°€ìŠ¤%'
                  OR dt.title LIKE '%ë°°ì¶œ%'
                  OR dt.title LIKE '%Scope%'
                  OR dt.title LIKE '%GHG%'
                  OR dt.title LIKE '%íƒ„ì†Œ%'
              )
            HAVING cell_count >= 30
            ORDER BY cell_count DESC
            LIMIT 15
        """

        tables = []
        with engine.connect() as conn:
            # í‚¤ì›Œë“œ í‘œ
            rows = conn.execute(text(sql_keyword), {'doc_id': doc_id}).fetchall()
            tables.extend([
                {'id': r[0], 'title': r[1], 'page_no': r[2], 'cell_count': r[3], 'priority': r[4]}
                for r in rows
            ])

            # ë‚˜ë¨¸ì§€ í‘œ
            rows = conn.execute(text(sql_rest), {'doc_id': doc_id}).fetchall()
            tables.extend([
                {'id': r[0], 'title': r[1], 'page_no': r[2], 'cell_count': r[3], 'priority': r[4]}
                for r in rows
            ])

        # ìš°ì„ ìˆœìœ„ì™€ í˜ì´ì§€ ìˆœìœ¼ë¡œ ì •ë ¬
        tables.sort(key=lambda x: (x['priority'], x['page_no']))
        return tables

    def _extract_scope_1_2(self, doc_id: int, tables: List[Dict]) -> Optional[Dict]:
        """Scope 1, 2 ë°ì´í„° ì¶”ì¶œ"""

        # ìš°ì„ ìˆœìœ„: "ì˜¨ì‹¤ê°€ìŠ¤ ì´ ë°°ì¶œëŸ‰" ë˜ëŠ” "Scope 1&2" í¬í•¨ í‘œ
        priority_tables = [t for t in tables if 'ì´' in (t['title'] or '') or 'í˜„í™©' in (t['title'] or '')]
        search_tables = priority_tables if priority_tables else tables

        for table in search_tables:
            table_id = table['id']

            # ì—°ë„ ì»¬ëŸ¼ íƒì§€
            year_cols = self._detect_year_columns(table_id)
            if not year_cols:
                continue

            # Scope 1 row ì°¾ê¸°
            scope1_row = self._find_row_by_patterns(table_id, self.SCOPE1_PATTERNS)
            # Scope 2 row ì°¾ê¸°
            scope2_row = self._find_row_by_patterns(table_id, self.SCOPE2_PATTERNS)
            # Scope 1+2 í•©ê³„ row ì°¾ê¸°
            scope1_2_row = self._find_row_by_patterns(table_id, self.SCOPE1_2_PATTERNS)

            if scope1_row is None and scope2_row is None:
                continue

            # ìµœì‹  ì—°ë„ ë°ì´í„° ì¶”ì¶œ
            latest_year = max(year_cols.keys())
            latest_col = year_cols[latest_year]

            s1 = self._get_cell_value(table_id, scope1_row, latest_col) if scope1_row else None
            s2 = self._get_cell_value(table_id, scope2_row, latest_col) if scope2_row else None

            # ì—°ë„ë³„ ë°ì´í„° (Scope 1+2 í•©ê³„)
            yearly = {}
            if scope1_2_row is not None:
                for year, col in year_cols.items():
                    val = self._get_cell_value(table_id, scope1_2_row, col)
                    if val:
                        yearly[str(year)] = val

            # ê¸°ì¤€ì—°ë„ ì°¾ê¸° (ë§ˆì§€ë§‰ ì»¬ëŸ¼ì´ ë³´í†µ ê¸°ì¤€ì—°ë„)
            base_year = None
            base_emissions = None
            if year_cols:
                # "ê¸°ì¤€ì—°ë„" ë˜ëŠ” ê°€ì¥ ì˜¤ë˜ëœ ì—°ë„
                sorted_years = sorted(year_cols.keys())
                if sorted_years[0] < 2020:  # 2019, 2020 ë“±ì´ë©´ ê¸°ì¤€ì—°ë„
                    base_year = sorted_years[0]
                    if scope1_2_row is not None:
                        base_emissions = self._get_cell_value(table_id, scope1_2_row, year_cols[base_year])

            if s1 or s2:
                print(f"[Extractor] Table {table_id}: S1={s1}, S2={s2}")
                return {
                    'table_id': table_id,
                    's1': s1,
                    's2': s2,
                    'yearly': yearly,
                    'base_year': base_year,
                    'base_emissions': base_emissions
                }

        return None

    def _extract_scope_3(self, doc_id: int, tables: List[Dict]) -> Optional[Dict]:
        """Scope 3 ë°ì´í„° ì¶”ì¶œ"""

        # Scope 3 ê´€ë ¨ í‘œ ì°¾ê¸°
        scope3_tables = [t for t in tables if 'Scope' in (t['title'] or '') and '3' in (t['title'] or '')]
        if not scope3_tables:
            scope3_tables = tables

        for table in scope3_tables:
            table_id = table['id']

            year_cols = self._detect_year_columns(table_id)
            if not year_cols:
                continue

            scope3_row = self._find_row_by_patterns(table_id, self.SCOPE3_PATTERNS)
            if scope3_row is None:
                continue

            latest_year = max(year_cols.keys())
            latest_col = year_cols[latest_year]

            # Scope 3ëŠ” ì—¬ëŸ¬ ì»¬ëŸ¼ ì¤‘ "í˜„ëŒ€ê±´ì„¤" ì»¬ëŸ¼ì„ ì°¾ì•„ì•¼ í•  ìˆ˜ë„ ìˆìŒ
            s3 = self._get_cell_value(table_id, scope3_row, latest_col)

            if s3:
                print(f"[Extractor] Table {table_id}: S3={s3}")
                return {
                    'table_id': table_id,
                    's3': s3
                }

        return None

    def _extract_revenue(self, doc_id: int) -> Optional[Dict]:
        """ë§¤ì¶œì•¡ ì¶”ì¶œ (íšŒì‚¬ ê°œìš” í‘œì—ì„œ)"""

        # "ê°œìš”" ë˜ëŠ” "í˜„í™©" í‘œ ì°¾ê¸°
        sql = """
            SELECT dt.id, dt.title
            FROM doc_tables dt
            WHERE dt.doc_id = :doc_id
              AND (dt.title LIKE '%ê°œìš”%' OR dt.title LIKE '%í˜„í™©%' OR dt.title LIKE '%ì¼ë°˜%')
            LIMIT 10
        """
        with engine.connect() as conn:
            tables = conn.execute(text(sql), {'doc_id': doc_id}).fetchall()

        for table_id, title in tables:
            # ë§¤ì¶œì•¡ í…ìŠ¤íŠ¸ ì°¾ê¸°
            sql = """
                SELECT content
                FROM table_cells
                WHERE table_id = :table_id
                  AND (content LIKE '%ì¡°%ì–µ%ì›%' OR content LIKE '%ë§¤ì¶œ%')
                ORDER BY row_idx
            """
            with engine.connect() as conn:
                rows = conn.execute(text(sql), {'table_id': table_id}).fetchall()

            for row in rows:
                content = row[0]
                revenue = self._parse_korean_currency(content)
                if revenue and revenue > 1000:  # ìµœì†Œ 1000ì–µ ì´ìƒ
                    print(f"[Extractor] Table {table_id}: Revenue={revenue}ì–µ")
                    return {
                        'table_id': table_id,
                        'revenue': revenue
                    }

        return None

    def _extract_with_gpt(self, doc_id: int, tables: List[Dict]) -> Optional[Dict]:
        """
        GPT APIë¥¼ ì‚¬ìš©í•˜ì—¬ ë°°ì¶œëŸ‰ ë°ì´í„° ì¶”ì¶œ
        ì •ê·œì‹ë³´ë‹¤ ë” ìœ ì—°í•˜ê²Œ ë‹¤ì–‘í•œ í‘œ í˜•ì‹ ì²˜ë¦¬ ê°€ëŠ¥
        """
        if not tables:
            return None

        result = {'source_tables': {}}

        # ìƒìœ„ 10ê°œ í‘œ ì²˜ë¦¬ (í‚¤ì›Œë“œ í‘œ ìš°ì„ , ë¹„ìš© ì•½ $0.01)
        for table in tables[:10]:
            table_id = table['id']
            table_text = self._format_table_for_gpt(table_id)

            if not table_text or len(table_text) < 50:
                continue

            prompt = f"""ë‹¤ìŒì€ ESG ë³´ê³ ì„œì˜ í‘œì…ë‹ˆë‹¤. ì•„ë˜ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì—¬ JSONìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”.

## ì¶”ì¶œ ëŒ€ìƒ
- scope1: Scope 1 (ì§ì ‘ ë°°ì¶œëŸ‰) - ê°€ì¥ ìµœì‹  ì—°ë„ ê°’ (ë‹¨ìœ„: tCO2e)
- scope2: Scope 2 (ê°„ì ‘ ë°°ì¶œëŸ‰) - ê°€ì¥ ìµœì‹  ì—°ë„ ê°’ (ë‹¨ìœ„: tCO2e)
- scope3: Scope 3 (ê¸°íƒ€ ê°„ì ‘ ë°°ì¶œëŸ‰) - ìˆìœ¼ë©´ ì¶”ì¶œ (ë‹¨ìœ„: tCO2e)
- yearly_emissions: ì—°ë„ë³„ ì´ ë°°ì¶œëŸ‰ (Scope 1+2 í•©ê³„) ë”•ì…”ë„ˆë¦¬ {{"2021": 12345, "2022": 23456, ...}}
- base_year: ê¸°ì¤€ì—°ë„ (ìˆìœ¼ë©´)
- base_emissions: ê¸°ì¤€ì—°ë„ ë°°ì¶œëŸ‰

## ê·œì¹™
1. ìˆ«ìë§Œ ë°˜í™˜ (ë‹¨ìœ„, ì½¤ë§ˆ ì œì™¸)
2. ê°’ì„ ì°¾ì§€ ëª»í•˜ë©´ í•´ë‹¹ í•„ë“œëŠ” null
3. "ì§ì ‘ ì˜¨ì‹¤ê°€ìŠ¤", "ì§ì ‘ë°°ì¶œ", "Scope 1" ë“±ì€ ëª¨ë‘ Scope 1
4. "ê°„ì ‘ ì˜¨ì‹¤ê°€ìŠ¤", "ê°„ì ‘ë°°ì¶œ", "Scope 2" ë“±ì€ ëª¨ë‘ Scope 2
5. **ì¤‘ìš”**: í‘œì— ì—¬ëŸ¬ ì—°ë„(2021, 2022, 2023, 2024 ë“±)ê°€ ìˆìœ¼ë©´, "ê¸°ì¤€ì—°ë„" ì»¬ëŸ¼ì„ ì œì™¸í•˜ê³  ê°€ì¥ í° ìˆ«ì ì—°ë„ì˜ ê°’ì„ ì‚¬ìš© (ì˜ˆ: 2024 > 2023)
6. ì—°ë„ í—¤ë”ì— "2024 1)" ê°™ì€ ì£¼ì„ì´ ìˆì–´ë„ ìˆ«ìë§Œ ë³´ê³  íŒë‹¨
7. "êµ­ë‚´", "í•´ì™¸" ë“± í•˜ìœ„ í•­ëª© ì•„ë‹Œ ìƒìœ„ í•©ê³„ í–‰ ê°’ ì‚¬ìš©

## í‘œ ë°ì´í„°
{table_text}

## ì‘ë‹µ í˜•ì‹ (JSONë§Œ, ì„¤ëª… ì—†ì´)
{{"scope1": ìˆ«ì|null, "scope2": ìˆ«ì|null, "scope3": ìˆ«ì|null, "yearly_emissions": {{}}|null, "base_year": ìˆ«ì|null, "base_emissions": ìˆ«ì|null}}
"""
            try:
                response = openai_client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=[
                        {"role": "system", "content": "ESG ë³´ê³ ì„œ ë°ì´í„° ì¶”ì¶œ ì „ë¬¸ê°€. JSONë§Œ ë°˜í™˜."},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0,
                    max_tokens=500
                )

                content = response.choices[0].message.content.strip()
                # JSON íŒŒì‹± (ì½”ë“œë¸”ë¡ ì œê±°)
                if content.startswith("```"):
                    content = re.sub(r'^```json?\s*', '', content)
                    content = re.sub(r'```\s*$', '', content)

                data = json.loads(content)
                print(f"[GPT] Table {table_id} ì¶”ì¶œ: {data}")

                # ê²°ê³¼ ë³‘í•©
                if data.get('scope1') and not result.get('s1'):
                    result['s1'] = float(data['scope1'])
                    result['source_tables']['s1'] = table_id

                if data.get('scope2') and not result.get('s2'):
                    result['s2'] = float(data['scope2'])
                    result['source_tables']['s2'] = table_id

                if data.get('scope3') and not result.get('s3'):
                    result['s3'] = float(data['scope3'])
                    result['source_tables']['s3'] = table_id

                if data.get('yearly_emissions') and not result.get('yearly_emissions'):
                    # ì—°ë„ë³„ ë°ì´í„° ì •ê·œí™” (ë¬¸ìì—´ í‚¤ â†’ ì •ìˆ˜ ê°’)
                    yearly = {}
                    for year, val in data['yearly_emissions'].items():
                        if val:
                            yearly[str(year)] = float(val)
                    if yearly:
                        result['yearly_emissions'] = yearly

                if data.get('base_year') and not result.get('base_year'):
                    result['base_year'] = int(data['base_year'])

                if data.get('base_emissions') and not result.get('base_emissions'):
                    result['base_emissions'] = float(data['base_emissions'])

                # Scope 1, 2 ë‘˜ ë‹¤ ì°¾ì•˜ìœ¼ë©´ ì¡°ê¸° ì¢…ë£Œ
                if result.get('s1') and result.get('s2'):
                    break

            except json.JSONDecodeError as e:
                print(f"[GPT] Table {table_id} JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
                continue
            except Exception as e:
                print(f"[GPT] Table {table_id} API ì˜¤ë¥˜: {e}")
                continue

        # ìµœì†Œí•œ s1 ë˜ëŠ” s2ê°€ ìˆì–´ì•¼ ì„±ê³µ
        if result.get('s1') or result.get('s2'):
            return result

        return None

    def _format_table_for_gpt(self, table_id: int) -> str:
        """í‘œ ì…€ì„ GPTê°€ ì´í•´í•  ìˆ˜ ìˆëŠ” í…ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        sql = """
            SELECT row_idx, col_idx, content
            FROM table_cells
            WHERE table_id = :table_id
            ORDER BY row_idx, col_idx
        """
        with engine.connect() as conn:
            rows = conn.execute(text(sql), {'table_id': table_id}).fetchall()

        if not rows:
            return ""

        # í–‰ë³„ë¡œ ê·¸ë£¹í™”
        table_data = {}
        for row_idx, col_idx, content in rows:
            if row_idx not in table_data:
                table_data[row_idx] = {}
            table_data[row_idx][col_idx] = content or ""

        # ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸” í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        lines = []
        for row_idx in sorted(table_data.keys()):
            row = table_data[row_idx]
            cols = [row.get(c, "") for c in range(max(row.keys()) + 1)]
            lines.append(" | ".join(str(c)[:50] for c in cols))  # ì…€ë‹¹ 50ì ì œí•œ

        return "\n".join(lines[:30])  # ìµœëŒ€ 30í–‰

    def _extract_with_gpt_vision(self, doc_id: int, tables: List[Dict]) -> Optional[Dict]:
        """
        GPT-4Vë¥¼ ì‚¬ìš©í•˜ì—¬ í‘œ ì´ë¯¸ì§€ ì§ì ‘ ë¶„ì„
        docling ì¶”ì¶œ í’ˆì§ˆê³¼ ë¬´ê´€í•˜ê²Œ ì›ë³¸ ì´ë¯¸ì§€ë¡œ ì •í™•íˆ ì¶”ì¶œ
        """
        if not tables:
            return None

        result = {'source_tables': {}}

        # ìƒìœ„ 10ê°œ í‘œ ì²˜ë¦¬ (ì´ë¯¸ì§€ ë¶„ì„ì€ ë¹„ìš©ì´ ë†’ìœ¼ë¯€ë¡œ)
        for table in tables[:10]:
            table_id = table['id']

            # í‘œ ì´ë¯¸ì§€ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°
            image_path = self._get_table_image_path(table_id)
            if not image_path or not image_path.exists():
                print(f"[GPT-Vision] Table {table_id} ì´ë¯¸ì§€ ì—†ìŒ, ê±´ë„ˆëœ€")
                continue

            # ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©
            try:
                image_base64 = self._encode_image(image_path)
            except Exception as e:
                print(f"[GPT-Vision] Table {table_id} ì´ë¯¸ì§€ ì¸ì½”ë”© ì˜¤ë¥˜: {e}")
                continue

            # GPT-4V API í˜¸ì¶œ
            prompt = """ì´ í‘œ ì´ë¯¸ì§€ì—ì„œ ì˜¨ì‹¤ê°€ìŠ¤ ë°°ì¶œëŸ‰ ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.

**ì¤‘ìš”: ë°ì´í„°ê°€ ì—†ì–´ë„ ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”. ì„¤ëª…ì´ë‚˜ ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.**

## ì¶”ì¶œ ëŒ€ìƒ
- scope1: Scope 1 (ì§ì ‘ ë°°ì¶œëŸ‰) - ê°€ì¥ ìµœì‹  ì—°ë„ ê°’ (ë‹¨ìœ„: tCO2e)
- scope2: Scope 2 (ê°„ì ‘ ë°°ì¶œëŸ‰) - ê°€ì¥ ìµœì‹  ì—°ë„ ê°’ (ë‹¨ìœ„: tCO2e)
- scope3: Scope 3 (ê¸°íƒ€ ê°„ì ‘ ë°°ì¶œëŸ‰) - ìˆìœ¼ë©´ ì¶”ì¶œ (ë‹¨ìœ„: tCO2e)
- yearly_emissions: ì—°ë„ë³„ ì´ ë°°ì¶œëŸ‰ (Scope 1+2 í•©ê³„) ë”•ì…”ë„ˆë¦¬ {"2021": 12345, "2022": 23456, ...}
- base_year: ê¸°ì¤€ì—°ë„ (ìˆìœ¼ë©´)
- base_emissions: ê¸°ì¤€ì—°ë„ ë°°ì¶œëŸ‰

## ê·œì¹™
1. ìˆ«ìë§Œ ë°˜í™˜ (ë‹¨ìœ„, ì½¤ë§ˆ ì œê±°)
2. ê°’ì„ ì°¾ì§€ ëª»í•˜ë©´ í•´ë‹¹ í•„ë“œëŠ” null
3. "ì§ì ‘ ì˜¨ì‹¤ê°€ìŠ¤", "ì§ì ‘ë°°ì¶œ", "Scope 1" ë“±ì€ ëª¨ë‘ Scope 1
4. "ê°„ì ‘ ì˜¨ì‹¤ê°€ìŠ¤", "ê°„ì ‘ë°°ì¶œ", "Scope 2" ë“±ì€ ëª¨ë‘ Scope 2
5. í‘œì— ì—¬ëŸ¬ ì—°ë„ê°€ ìˆìœ¼ë©´, "ê¸°ì¤€ì—°ë„" ì»¬ëŸ¼ ì œì™¸í•˜ê³  ê°€ì¥ í° ìˆ«ì ì—°ë„ì˜ ê°’ ì‚¬ìš© (2024 > 2023)
6. "êµ­ë‚´", "í•´ì™¸" ë“± í•˜ìœ„ í•­ëª©ì´ ì•„ë‹Œ ìƒìœ„ í•©ê³„ í–‰ì˜ ê°’ ì‚¬ìš©

## ì‘ë‹µ í˜•ì‹ (JSONë§Œ, ì„¤ëª… ì—†ì´)
{"scope1": ìˆ«ì|null, "scope2": ìˆ«ì|null, "scope3": ìˆ«ì|null, "yearly_emissions": {}|null, "base_year": ìˆ«ì|null, "base_emissions": ìˆ«ì|null}
"""

            try:
                response = openai_client.chat.completions.create(
                    model="gpt-4o",  # GPT-4V ì§€ì› ëª¨ë¸
                    messages=[
                        {
                            "role": "user",
                            "content": [
                                {"type": "text", "text": prompt},
                                {
                                    "type": "image_url",
                                    "image_url": {
                                        "url": f"data:image/png;base64,{image_base64}",
                                        "detail": "high"  # ê³ í•´ìƒë„ ë¶„ì„
                                    }
                                }
                            ]
                        }
                    ],
                    max_tokens=500,
                    temperature=0
                )

                content = response.choices[0].message.content.strip()
                print(f"[GPT-Vision] Table {table_id} ì‘ë‹µ: {content[:200]}...")

                # JSON íŒŒì‹± (ì½”ë“œë¸”ë¡ ì œê±°)
                if content.startswith("```"):
                    content = re.sub(r'^```json?\s*', '', content)
                    content = re.sub(r'```\s*$', '', content)

                data = json.loads(content)
                print(f"[GPT-Vision] Table {table_id} ì¶”ì¶œ: {data}")

                # ê²°ê³¼ ë³‘í•©
                if data.get('scope1') and not result.get('s1'):
                    result['s1'] = float(data['scope1'])
                    result['source_tables']['s1'] = table_id

                if data.get('scope2') and not result.get('s2'):
                    result['s2'] = float(data['scope2'])
                    result['source_tables']['s2'] = table_id

                if data.get('scope3') and not result.get('s3'):
                    result['s3'] = float(data['scope3'])
                    result['source_tables']['s3'] = table_id

                if data.get('yearly_emissions') and not result.get('yearly_emissions'):
                    yearly = {}
                    for year, val in data['yearly_emissions'].items():
                        if val:
                            yearly[str(year)] = float(val)
                    if yearly:
                        result['yearly_emissions'] = yearly

                if data.get('base_year') and not result.get('base_year'):
                    result['base_year'] = int(data['base_year'])

                if data.get('base_emissions') and not result.get('base_emissions'):
                    result['base_emissions'] = float(data['base_emissions'])

                # Scope 1, 2 ë‘˜ ë‹¤ ì°¾ì•˜ìœ¼ë©´ ì¡°ê¸° ì¢…ë£Œ
                if result.get('s1') and result.get('s2'):
                    break

            except json.JSONDecodeError as e:
                print(f"[GPT-Vision] Table {table_id} JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
                continue
            except Exception as e:
                print(f"[GPT-Vision] Table {table_id} API ì˜¤ë¥˜: {e}")
                continue

        # ìµœì†Œí•œ s1 ë˜ëŠ” s2ê°€ ìˆì–´ì•¼ ì„±ê³µ
        if result.get('s1') or result.get('s2'):
            return result

        return None

    def _get_table_image_path(self, table_id: int) -> Optional[Path]:
        """í‘œ ì´ë¯¸ì§€ ê²½ë¡œ ì¡°íšŒ ë° ì ˆëŒ€ ê²½ë¡œ ë°˜í™˜"""
        sql = """
            SELECT dt.image_path, d.filename
            FROM doc_tables dt
            JOIN documents d ON dt.doc_id = d.id
            WHERE dt.id = :table_id
        """
        with engine.connect() as conn:
            result = conn.execute(text(sql), {'table_id': table_id}).fetchone()

        if not result or not result[0]:
            return None

        image_rel_path = result[0]  # ì˜ˆ: "page_0050/tables/table_001.png"
        filename = result[1]  # ì˜ˆ: "2025_HDEC_Report.pdf"

        # íŒŒì¼ëª…ì—ì„œ .pdf ì œê±°
        doc_name = filename.replace('.pdf', '')

        # ì „ì²´ ê²½ë¡œ êµ¬ì„±: pages_structured/2025_HDEC_Report/page_0050/tables/table_001.png
        abs_path = STRUCTURED_DATA_PATH / doc_name / image_rel_path

        return abs_path if abs_path.exists() else None

    def _encode_image(self, image_path: Path) -> str:
        """ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©"""
        with open(image_path, "rb") as image_file:
            return base64.b64encode(image_file.read()).decode('utf-8')

    def _detect_year_columns(self, table_id: int) -> Dict[int, int]:
        """í—¤ë” í–‰ì—ì„œ ì—°ë„ ì»¬ëŸ¼ ìë™ íƒì§€"""
        sql = """
            SELECT col_idx, content
            FROM table_cells
            WHERE table_id = :table_id
              AND row_idx = 0
            ORDER BY col_idx
        """
        year_cols = {}
        with engine.connect() as conn:
            rows = conn.execute(text(sql), {'table_id': table_id}).fetchall()

        for col_idx, content in rows:
            if not content:
                continue
            # "2021", "2022ë…„", "2023 1)", "ê¸°ì¤€ì—°ë„ (2019/2020)" ë“± íŒ¨í„´
            match = re.search(r'(20\d{2})', content)
            if match:
                year = int(match.group(1))
                year_cols[year] = col_idx

        return year_cols

    def _find_row_by_patterns(self, table_id: int, patterns: List[str]) -> Optional[int]:
        """col0(í—¤ë” ì»¬ëŸ¼)ì—ì„œ íŒ¨í„´ ë§¤ì¹­í•˜ì—¬ row_idx ë°˜í™˜"""
        sql = """
            SELECT row_idx, content
            FROM table_cells
            WHERE table_id = :table_id
              AND col_idx = 0
              AND content IS NOT NULL
            ORDER BY row_idx
        """
        with engine.connect() as conn:
            rows = conn.execute(text(sql), {'table_id': table_id}).fetchall()

        for row_idx, content in rows:
            for pattern in patterns:
                if re.search(pattern, content, re.IGNORECASE):
                    return row_idx

        return None

    def _get_cell_value(self, table_id: int, row_idx: int, col_idx: int) -> Optional[float]:
        """íŠ¹ì • ì…€ì˜ numeric_value ë°˜í™˜"""
        if row_idx is None or col_idx is None:
            return None

        sql = """
            SELECT numeric_value, content
            FROM table_cells
            WHERE table_id = :table_id AND row_idx = :row AND col_idx = :col
        """
        with engine.connect() as conn:
            result = conn.execute(text(sql), {
                'table_id': table_id,
                'row': row_idx,
                'col': col_idx
            }).fetchone()

        if result:
            if result[0]:  # numeric_valueê°€ ìˆìœ¼ë©´
                return float(result[0])
            # numeric_valueê°€ ì—†ìœ¼ë©´ contentì—ì„œ íŒŒì‹± ì‹œë„
            if result[1]:
                return self._parse_number(result[1])

        return None

    def _parse_number(self, text: str) -> Optional[float]:
        """í…ìŠ¤íŠ¸ì—ì„œ ìˆ«ì ì¶”ì¶œ"""
        if not text:
            return None
        # ì‰¼í‘œ ì œê±°í•˜ê³  ìˆ«ì ì¶”ì¶œ
        clean = re.sub(r'[^\d.-]', '', text.replace(',', ''))
        try:
            return float(clean)
        except:
            return None

    def _parse_korean_currency(self, text: str) -> Optional[float]:
        """
        í•œêµ­ì–´ ê¸ˆì•¡ í‘œê¸°ë¥¼ ì–µì› ë‹¨ìœ„ ìˆ«ìë¡œ ë³€í™˜
        "32ì¡°6,703ì–µ ì›" â†’ 326703.0
        """
        if not text:
            return None

        text = text.replace(',', '').replace(' ', '')

        # ì¡° + ì–µ
        match = re.search(r'(\d+)ì¡°(\d+)ì–µ', text)
        if match:
            return int(match.group(1)) * 10000 + int(match.group(2))

        # ì¡°ë§Œ
        match = re.search(r'(\d+)ì¡°', text)
        if match:
            return int(match.group(1)) * 10000

        # ì–µë§Œ
        match = re.search(r'(\d+)ì–µ', text)
        if match:
            return int(match.group(1))

        return None

    def extract_and_save_auto(self, doc_id: int) -> Dict[str, Any]:
        """
        ìë™ ì¶”ì¶œ ë° ì €ì¥ íŒŒì´í”„ë¼ì¸
        1. GPT-4o-minië¡œ ëª¨ë“  í‘œ ì´ë¯¸ì§€ ìŠ¤ìº” (ë¹ ë¥´ê³  ì €ë ´)
        2. ê´€ë ¨ë„ ì ìˆ˜ë¡œ ìƒìœ„ í›„ë³´ ì„ íƒ
        3. GPT-4oë¡œ ì •ë°€ ë¶„ì„
        4. DBì— ìë™ ì €ì¥
        """
        print("=" * 60)
        print("ìë™ ì¶”ì¶œ ë° ì €ì¥ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
        print("=" * 60)

        # 1. ëª¨ë“  í‘œ ê°€ì ¸ì˜¤ê¸° (ì´ë¯¸ì§€ ìˆëŠ” ê²ƒë§Œ)
        all_tables = self._find_all_tables_with_images(doc_id)
        print(f"\n[Step 1] ì´ë¯¸ì§€ ìˆëŠ” í‘œ {len(all_tables)}ê°œ ë°œê²¬")

        if not all_tables:
            print("ì´ë¯¸ì§€ê°€ ìˆëŠ” í‘œê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None

        # 2. GPT-4o-minië¡œ ê´€ë ¨ë„ ì ìˆ˜ ë§¤ê¸°ê¸°
        print(f"\n[Step 2] GPT-4o-minië¡œ ê´€ë ¨ë„ ì ìˆ˜ ê³„ì‚° ì¤‘...")
        scored_tables = self._score_tables_for_relevance(all_tables)

        # ì ìˆ˜ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬
        scored_tables.sort(key=lambda x: x['score'], reverse=True)

        print(f"\nìƒìœ„ 5ê°œ í›„ë³´:")
        for i, t in enumerate(scored_tables[:5], 1):
            title = (t.get('title') or 'No title')[:50]
            print(f"  {i}. Table {t['id']} (ì ìˆ˜: {t['score']}/100) - {title}")

        # 3. ìƒìœ„ í›„ë³´ë§Œ GPT-4oë¡œ ì •ë°€ ë¶„ì„
        print(f"\n[Step 3] ìƒìœ„ í›„ë³´ GPT-4o ì •ë°€ ë¶„ì„ ì¤‘...")
        candidates = [t for t in scored_tables if t['score'] >= 60][:5]  # ì ìˆ˜ 60 ì´ìƒ, ìµœëŒ€ 5ê°œ

        if not candidates:
            print(f"ì ìˆ˜ 60 ì´ìƒì¸ í‘œê°€ ì—†ìŠµë‹ˆë‹¤. ìƒìœ„ 3ê°œë¡œ ì‹œë„...")
            candidates = scored_tables[:3]

        # í›„ë³´ í‘œë§Œ GPT-Visionìœ¼ë¡œ ë¶„ì„
        result = {'source_tables': {}, 'data_source': 'gpt-vision-auto'}
        result.update(self._get_document_info(doc_id))
        result['doc_id'] = doc_id
        result['data_year'] = result.get('report_year', 2024) - 1

        gpt_data = self._extract_with_gpt_vision(doc_id, candidates)

        if not gpt_data:
            print("GPT-Visionìœ¼ë¡œ ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨, ì •ê·œì‹ fallback ì‹œë„...")
            return self.extract_for_document(doc_id, use_gpt=False)

        result.update(gpt_data)
        data = result

        # 4. DBì— ì €ì¥
        if data and (data.get('s1') or data.get('s2')):
            print(f"\n[Step 4] DBì— ì €ì¥ ì¤‘...")
            self.save_to_summary(data)
            print(f"âœ… ì €ì¥ ì™„ë£Œ: {data.get('company_name')} {data.get('report_year')}")
            return data
        else:
            print("ì¶”ì¶œëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None

    def _find_all_tables_with_images(self, doc_id: int) -> List[Dict]:
        """ì´ë¯¸ì§€ê°€ ìˆëŠ” í‘œë§Œ ê°€ì ¸ì˜¤ê¸°"""
        sql = """
            SELECT dt.id, dt.title, dt.page_no, dt.image_path,
                   (SELECT COUNT(*) FROM table_cells tc WHERE tc.table_id = dt.id) as cell_count,
                   d.filename
            FROM doc_tables dt
            JOIN documents d ON dt.doc_id = d.id
            WHERE dt.doc_id = :doc_id
              AND dt.image_path IS NOT NULL
            ORDER BY dt.page_no
        """
        with engine.connect() as conn:
            rows = conn.execute(text(sql), {'doc_id': doc_id}).fetchall()

        tables = []
        for r in rows:
            table_id, title, page_no, image_path, cell_count, filename = r

            # ì‹¤ì œ ì´ë¯¸ì§€ íŒŒì¼ ì¡´ì¬ í™•ì¸
            doc_name = filename.replace('.pdf', '')
            abs_path = STRUCTURED_DATA_PATH / doc_name / image_path

            if abs_path.exists():
                tables.append({
                    'id': table_id,
                    'title': title,
                    'page_no': page_no,
                    'image_path': str(abs_path),
                    'cell_count': cell_count
                })

        return tables

    def _score_tables_for_relevance(self, tables: List[Dict]) -> List[Dict]:
        """GPT-4o-minië¡œ ê° í‘œì˜ ê´€ë ¨ë„ ì ìˆ˜ ë§¤ê¸°ê¸°"""
        scored = []

        for table in tables:
            try:
                # ì´ë¯¸ì§€ ì¸ì½”ë”©
                image_base64 = self._encode_image(Path(table['image_path']))

                # GPT-4o-minië¡œ ë¹ ë¥´ê²Œ ì ìˆ˜ ë§¤ê¸°ê¸°
                prompt = """ì´ í‘œê°€ ì˜¨ì‹¤ê°€ìŠ¤ ë°°ì¶œëŸ‰ ë°ì´í„°(Scope 1, 2, 3)ë¥¼ í¬í•¨í•˜ê³  ìˆì„ ê°€ëŠ¥ì„±ì„ 0-100 ì ìˆ˜ë¡œ í‰ê°€í•˜ì„¸ìš”.

## í‰ê°€ ê¸°ì¤€
- 100ì : Scope 1, 2, 3 ë°°ì¶œëŸ‰ì´ ëª…í™•íˆ í‘œì‹œë¨
- 80-90ì : ì˜¨ì‹¤ê°€ìŠ¤/ë°°ì¶œëŸ‰ ê´€ë ¨ ìˆ˜ì¹˜ê°€ ìˆìŒ
- 50-70ì : í™˜ê²½ ê´€ë ¨ ë°ì´í„°ì´ì§€ë§Œ ë°°ì¶œëŸ‰ì€ ë¶ˆí™•ì‹¤
- 30-50ì : ì¼ë°˜ ESG ì§€í‘œ (ì—ë„ˆì§€, íê¸°ë¬¼ ë“±)
- 0-30ì : ë°°ì¶œëŸ‰ê³¼ ë¬´ê´€ (ì¬ë¬´, ì¸ì‚¬, ê°œìš” ë“±)

**ë°˜ë“œì‹œ ìˆ«ìë§Œ ë°˜í™˜í•˜ì„¸ìš” (ì˜ˆ: 85)**
"""

                response = openai_client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=[
                        {
                            "role": "user",
                            "content": [
                                {"type": "text", "text": prompt},
                                {
                                    "type": "image_url",
                                    "image_url": {
                                        "url": f"data:image/png;base64,{image_base64}",
                                        "detail": "low"  # ì €í•´ìƒë„ë¡œ ë¹ ë¥´ê²Œ
                                    }
                                }
                            ]
                        }
                    ],
                    max_tokens=10,
                    temperature=0
                )

                score_text = response.choices[0].message.content.strip()
                # ìˆ«ìë§Œ ì¶”ì¶œ
                score = int(re.search(r'\d+', score_text).group())

                table['score'] = score
                scored.append(table)
                print(f"  Table {table['id']}: {score}ì ")

            except Exception as e:
                print(f"  Table {table['id']}: ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨ ({e})")
                table['score'] = 0
                scored.append(table)

        return scored

    def save_to_summary(self, data: Dict[str, Any]) -> int:
        """ì¶”ì¶œëœ ë°ì´í„°ë¥¼ emission_summary í…Œì´ë¸”ì— ì €ì¥"""
        sql = """
            INSERT INTO emission_summary
            (doc_id, company_name, report_year, data_year,
             s1, s2, s3, yearly_emissions, base_year, base_emissions,
             revenue, allowance, source_tables, data_source)
            VALUES
            (:doc_id, :company_name, :report_year, :data_year,
             :s1, :s2, :s3, :yearly_emissions, :base_year, :base_emissions,
             :revenue, :allowance, :source_tables, :data_source)
            ON DUPLICATE KEY UPDATE
                s1 = VALUES(s1),
                s2 = VALUES(s2),
                s3 = VALUES(s3),
                yearly_emissions = VALUES(yearly_emissions),
                base_year = VALUES(base_year),
                base_emissions = VALUES(base_emissions),
                revenue = VALUES(revenue),
                allowance = VALUES(allowance),
                source_tables = VALUES(source_tables),
                data_source = VALUES(data_source),
                updated_at = CURRENT_TIMESTAMP
        """

        params = {
            'doc_id': data.get('doc_id'),
            'company_name': data.get('company_name'),
            'report_year': data.get('report_year'),
            'data_year': data.get('data_year'),
            's1': data.get('s1'),
            's2': data.get('s2'),
            's3': data.get('s3'),
            'yearly_emissions': json.dumps(data.get('yearly_emissions', {})),
            'base_year': data.get('base_year'),
            'base_emissions': data.get('base_emissions'),
            'revenue': data.get('revenue'),
            'allowance': data.get('allowance'),
            'source_tables': json.dumps(data.get('source_tables', {})),
            'data_source': data.get('data_source', 'auto')
        }

        with engine.connect() as conn:
            result = conn.execute(text(sql), params)
            conn.commit()
            print(f"[Extractor] Saved to emission_summary: {data.get('company_name')} {data.get('report_year')}")
            return result.rowcount


# CLI í…ŒìŠ¤íŠ¸ìš©
if __name__ == "__main__":
    import sys

    extractor = EmissionExtractor()

    # ì¸ìë¡œ ëª¨ë“œ ì„ íƒ: python emission_extractor.py [regex|gpt|vision|auto] [--save]
    args = [arg.lower() for arg in sys.argv[1:]]

    # AUTO ëª¨ë“œ: ìë™ ì¶”ì¶œ ë° ì €ì¥
    if 'auto' in args:
        print("ğŸ¤– ìë™ ì¶”ì¶œ ëª¨ë“œ")
        doc_id = 2  # ê¸°ë³¸ê°’

        # doc_id ì§€ì • ê°€ëŠ¥: python ... auto --doc-id=4
        for arg in sys.argv[1:]:
            if arg.startswith('--doc-id='):
                doc_id = int(arg.split('=')[1])

        result = extractor.extract_and_save_auto(doc_id)

        if result:
            print("\n" + "=" * 60)
            print("âœ… ì¶”ì¶œ ë° ì €ì¥ ì™„ë£Œ!")
            print("=" * 60)
            print(f"íšŒì‚¬: {result.get('company_name')}")
            print(f"S1: {result.get('s1')}")
            print(f"S2: {result.get('s2')}")
            print(f"S3: {result.get('s3')}")
            print(f"Revenue: {result.get('revenue')}")
        else:
            print("\nâŒ ì¶”ì¶œ ì‹¤íŒ¨")

        sys.exit(0)

    # ì¼ë°˜ ëª¨ë“œ
    if 'vision' in args:
        use_gpt = 'vision'
        mode = "GPT-4V ì´ë¯¸ì§€"
    elif 'gpt' in args:
        use_gpt = True
        mode = "GPT í…ìŠ¤íŠ¸"
    else:
        use_gpt = False
        mode = "ì •ê·œì‹"

    auto_save = '--save' in args

    # HDEC 2025 ë³´ê³ ì„œ (doc_id=2) í…ŒìŠ¤íŠ¸
    print("=" * 60)
    print(f"HDEC ë°ì´í„° ì¶”ì¶œ í…ŒìŠ¤íŠ¸ [{mode} ëª¨ë“œ]")
    print("=" * 60)

    data = extractor.extract_for_document(doc_id=2, use_gpt=use_gpt)

    print("\nì¶”ì¶œ ê²°ê³¼:")
    for k, v in data.items():
        print(f"  {k}: {v}")

    # DBì— ì €ì¥
    if auto_save:
        print("\nìë™ ì €ì¥ ì¤‘...")
        extractor.save_to_summary(data)
        print("ì €ì¥ ì™„ë£Œ!")
    else:
        print("\n* DBì— ì €ì¥í•˜ë ¤ë©´ --save í”Œë˜ê·¸ë¥¼ ì¶”ê°€í•˜ì„¸ìš”.")
        print("\nì‚¬ìš©ë²•:")
        print("  ì •ê·œì‹:      python3 -m app.services.emission_extractor")
        print("  GPT í…ìŠ¤íŠ¸:  python3 -m app.services.emission_extractor gpt")
        print("  GPT ë¹„ì „:    python3 -m app.services.emission_extractor vision")
        print("  ğŸ¤– ìë™ ì¶”ì¶œ: python3 -m app.services.emission_extractor auto")
        print("  ì €ì¥:        python3 -m app.services.emission_extractor vision --save")
