import pandas as pd
import FinanceDataReader as fdr
import yfinance as yf
from yahoo_fin import stock_info as si
from datetime import datetime, timedelta
import asyncio
from typing import List, Dict, Any, Optional
import httpx
from ..config import settings

class MarketDataService:
    # Class-level cache (shared across requests)
    _cache = {} 
    _last_updated = None
    _is_updating = False

    def __init__(self):
        pass

    async def preload_data(self):
        """Preload 3 years of data on server startup."""
        print("â³ [System] Preloading 3-year market data... (This may take a few seconds)")
        # Use a slightly longer timeout for initial load
        data = await self._fetch_dual_market_data_async(days=1095)
        MarketDataService._cache = data
        MarketDataService._last_updated = datetime.now()
        print(f"âœ… [System] Market data cached! ({len(data)} rows)")

    async def _fetch_dual_market_data_async(self, days=365):
        """Async wrapper for the fetch logic to avoid blocking event loop"""
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(None, self._fetch_dual_market_data, days)

    def _fetch_dual_market_data(self, days=365):
        """
        Fetch market data with 4-layer fallback:
        Alpha Vantage -> yfinance -> yahoo_fin -> FDR (Korea)
        """
        end_date = datetime.now()
        start_date = end_date - timedelta(days=days)

        # ==========================================
        # ðŸ‡ªðŸ‡º 1. EU-ETS (European Carbon Permits)
        # ==========================================
        eu_series = pd.Series(dtype=float)
        
        # [Try 1] CO2.L â€” WisdomTree Carbon ETP (EUR, LSE, EU ETS ì§ì ‘ ì¶”ì¢…)
        try:
            eu_df = yf.download("CO2.L", start=start_date, end=end_date, progress=False)
            if not eu_df.empty:
                if isinstance(eu_df.columns, pd.MultiIndex):
                    eu_series = eu_df['Close'].iloc[:, 0]
                else:
                    eu_series = eu_df['Close']
                print(f"âœ… CO2.L (EU-ETS) success: {len(eu_series)} rows")
        except Exception as e:
            print(f"âš ï¸ CO2.L EU failed: {e}")

        # [Try 2] FCO2.DE â€” EEX Carbon Future on Xetra
        if eu_series.empty:
            try:
                eu_df = yf.download("FCO2.DE", start=start_date, end=end_date, progress=False)
                if not eu_df.empty:
                    if isinstance(eu_df.columns, pd.MultiIndex):
                        eu_series = eu_df['Close'].iloc[:, 0]
                    else:
                        eu_series = eu_df['Close']
                    print(f"âœ… FCO2.DE (EU-ETS) success: {len(eu_series)} rows")
            except Exception as e:
                print(f"âš ï¸ FCO2.DE EU failed: {e}")

        # [Try 3] yahoo_fin (Web Scraping Last Backup)
        if eu_series.empty:
            try:
                print("ðŸ”„ Switching to yahoo_fin backup for EU-ETS...")
                eu_df_backup = si.get_data("CO2.L", start_date=start_date, end_date=end_date)
                eu_series = eu_df_backup['close']
                print("âœ… yahoo_fin EU success!")
            except Exception as e:
                print(f"âš ï¸ yahoo_fin EU failed: {e}")

        # ==========================================
        # ðŸ‡°ðŸ‡· 2. K-ETS (Korean Carbon Permits)
        # ==========================================
        kr_series = pd.Series(dtype=float)
        
        # [Try 1] FinanceDataReader (KRX KAU í˜„ë¬¼)
        try:
            df_krx = fdr.StockListing('KRX')
            kau_list = df_krx[df_krx['Name'].str.contains('KAU', case=False, na=False)]

            if not kau_list.empty:
                target_code = kau_list.sort_values(by='Code').iloc[-1]['Code']
                kr_df = fdr.DataReader(target_code, start=start_date, end=end_date)
                if not kr_df.empty:
                    kr_series = kr_df['Close']
                    print(f"âœ… FDR KAU ({target_code}) success: {len(kr_series)} rows")
        except Exception as e:
            print(f"âš ï¸ FDR KAU failed: {e}")

        # [Try 2] KODEX íƒ„ì†Œë°°ì¶œê¶Œ ETF (400590.KS) - yfinance proxy for K-ETS
        if kr_series.empty:
            try:
                kr_df = yf.download("400590.KS", start=start_date, end=end_date, progress=False)
                if not kr_df.empty:
                    if isinstance(kr_df.columns, pd.MultiIndex):
                        kr_series = kr_df['Close'].iloc[:, 0]
                    else:
                        kr_series = kr_df['Close']
                    kr_series = kr_series * 0.9  # ETF ê´´ë¦¬ ë³´ì •
                    print(f"âœ… yfinance 400590.KS (K-ETS ETFÃ—0.9 proxy) success: {len(kr_series)} rows")
            except Exception as e:
                print(f"âš ï¸ yfinance 400590.KS failed: {e}")

        # [Try 3] yahoo_fin (ìµœí›„ ë°±ì—…)
        if kr_series.empty:
            try:
                print("ðŸ”„ Switching to yahoo_fin backup for K-ETS...")
                kr_df_backup = si.get_data("400590.KS", start_date=start_date, end_date=end_date)
                kr_series = kr_df_backup['close'] * 0.9
                print("âœ… yahoo_fin K-ETS success!")
            except Exception as e:
                print(f"âš ï¸ yahoo_fin K-ETS failed: {e}")

        # Fallback for K-ETS: if everything fails, use recent static backup
        if kr_series.empty:
            print("âš ï¸ All K-ETS API failed, using static fallback.")
            dates = pd.date_range(start=start_date, end=end_date)
            kr_series = pd.Series(10500.0, index=dates)

        # ==========================================
        # 3. Merge & Format
        # ==========================================
        if eu_series.empty and kr_series.empty:
            print("âš ï¸ All data sources failed. Returning empty list.")
            return []

        df_merge = pd.DataFrame({"EU_ETS": eu_series, "K_ETS": kr_series})
        df_merge.sort_index(inplace=True)
        
        # âœ… ê¸ˆìœµ í‘œì¤€: 0.0ì„ NaNìœ¼ë¡œ ë³€í™˜ (ì‹¤ì œ ì—†ëŠ” ë°ì´í„°ë¡œ í‘œì‹œ)
        df_merge['EU_ETS'] = df_merge['EU_ETS'].replace(0.0, float('nan'))
        
        # âœ… ì „ì¼ ì¢…ê°€ë¡œ ì±„ìš°ê¸° (Forward Fill)
        # ì˜ˆ: 1ì¼(75ìœ ë¡œ) -> 2ì¼(ë°ì´í„°ì—†ìŒ) -> 2ì¼ë„ 75ìœ ë¡œë¡œ ì±„ì›€
        df_merge['EU_ETS'] = df_merge['EU_ETS'].ffill()
        
        # âœ… ë§¨ ì•ž ë°ì´í„°ë„ ì—†ë‹¤ë©´ ë’¤ì—ì„œ ê°€ì ¸ì˜¤ê¸° (Backward Fill)
        df_merge['EU_ETS'] = df_merge['EU_ETS'].bfill()
        
        # âœ… ì§„ì§œ ëª¨ë“  ë°ì´í„°ê°€ ì—†ë‹¤ë©´ ê³ ì •ê°’ (75.5ìœ ë¡œ)
        # ëžœë¤ë³´ë‹¤ ì¼ì§ì„ ì´ ë‚«ìŠµë‹ˆë‹¤.
        if df_merge['EU_ETS'].isnull().all():
            df_merge['EU_ETS'] = 75.5
            print("âš ï¸ No EU-ETS data available. Using fixed value: 75.5 EUR")
        
        # K-ETSë„ ë™ì¼í•˜ê²Œ ì²˜ë¦¬
        df_merge['K_ETS'] = df_merge['K_ETS'].replace(0.0, float('nan'))
        df_merge['K_ETS'] = df_merge['K_ETS'].ffill().bfill()
        
        # K-ETS ëª¨ë‘ ì—†ìœ¼ë©´ ê³ ì •ê°’ (13,000ì›)
        if df_merge['K_ETS'].isnull().all():
            df_merge['K_ETS'] = 13000
            print("âš ï¸ No K-ETS data available. Using fixed value: 13,000 KRW")

        result = []
        for date, row in df_merge.iterrows():
            eu_val = row['EU_ETS']
            kr_val = row['K_ETS']
            result.append({
                "date": date.strftime("%Y-%m-%d"),
                "EU-ETS": round(float(eu_val), 2),
                "K-ETS": int(kr_val)
            })
        return result

    async def get_dual_market_history(self, period: str = "1y"):
        """
        Return cached data. Refresh if expired.
        """
        # 1. Load if empty
        if not MarketDataService._cache:
            await self.preload_data()
        
        # 2. Refresh if older than 30 mins
        time_diff = datetime.now() - (MarketDataService._last_updated or datetime.min)
        if time_diff > timedelta(minutes=30): 
            print("ðŸ”„ [System] Cache expired. Refreshing market data...")
            # Run in background or wait? For simplicity, await it.
            new_data = await self._fetch_dual_market_data_async(days=1095)
            if new_data:
                MarketDataService._cache = new_data
                MarketDataService._last_updated = datetime.now()

        # 3. Slice based on period
        cached_data = MarketDataService._cache
        days_map = {"1m": 30, "3m": 90, "1y": 365, "all": 1095}
        req_days = days_map.get(period, 365)
        
        if len(cached_data) > req_days:
            return cached_data[-req_days:] 
        return cached_data

    def get_carbon_price_krx(self):
        """Current KRX price (Simple fallback logic)"""
        try:
            # Try getting recent K-ETS price first from cache or FDR
            if MarketDataService._cache:
                 last_item = MarketDataService._cache[-1]
                 if last_item["K-ETS"] > 0:
                     return {"price": float(last_item["K-ETS"]), "unit": "KRW", "source": "Cached"}
            
            # Fallback to direct ETF fetch
            df = fdr.DataReader('400590', datetime.now() - timedelta(days=7))
            if not df.empty:
                return {"price": float(df['Close'].iloc[-1]), "unit": "KRW", "source": "KRX_ETF"}
                
            return {"price": 10500.0, "unit": "KRW", "source": "Fallback_Fixed"}
        except:
            return {"price": 10500.0, "unit": "KRW", "source": "Fallback_Error"}

market_service = MarketDataService()
